"""
===============================================================================
üìä M√ìDULO DE REGRESI√ìN LINEAL M√öLTIPLE
===============================================================================

TEOR√çA MATEM√ÅTICA:
------------------
Objetivo: Predecir Tiempo_Real_Ofertado bas√°ndose en m√∫ltiples variables

Modelo matem√°tico:
    Tiempo = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑SPW + Œ≤‚ÇÇ¬∑Peso + Œ≤‚ÇÉ¬∑ANCHO_ASSY + Œ≤‚ÇÑ¬∑ALTO_ASSY + Œµ

Donde:
    Œ≤‚ÇÄ     = Intercept (tiempo base sin variables)
    Œ≤‚ÇÅ...Œ≤‚ÇÑ = Coeficientes (pesos) - PONDERACI√ìN de cada variable
    Œµ     = Error residual (lo que el modelo no explica)

C√ÅLCULO:
    El algoritmo M√≠nimos Cuadrados Ordinarios (OLS) encuentra los Œ≤ que 
    minimizan la suma de cuadrados del error:
    
    min Œ£(y·µ¢ - ≈∑·µ¢)¬≤  para i=1 a n
    
    Soluci√≥n (forma matricial):
    Œ≤ = (X^T¬∑X)‚Åª¬π¬∑X^T¬∑y

M√âTRICAS DE CALIDAD:
    ‚Ä¢ R¬≤ (Coef. Determinaci√≥n): 0-1. Qu√© % de varianza explica el modelo
    ‚Ä¢ RMSE: Error cuadr√°tico medio. Unidades: segundos
    ‚Ä¢ MAE: Error absoluto medio. Unidades: segundos
    ‚Ä¢ p-value: Significancia estad√≠stica. <0.05 = significativo

INTERPRETACI√ìN DE PESOS:
    Si Œ≤‚ÇÅ = 0.8 (SPW):
        ‚Üí Un punto SPW adicional aumenta el tiempo 0.8 segundos
    
    Si Œ≤‚ÇÇ = 2.5 (Peso):
        ‚Üí 1 kg adicional aumenta el tiempo 2.5 segundos
    
    Comparaci√≥n de impacto:
    2.5 / 0.8 = 3.125 ‚Üí El Peso es 3.125x m√°s importante que SPW

===============================================================================
"""

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, KFold
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import pickle
import json
from pathlib import Path
import matplotlib.pyplot as plt

class ModeloRegresionLineal:
    """
    Modelo de regresi√≥n lineal m√∫ltiple para estimar tiempos de ciclo.
    
    Atributos:
        modelo: Objeto LinearRegression de sklearn
        scaler: StandardScaler para normalizar variables
        variables_entrada: Lista de variables usadas como entrada
        variable_salida: Nombre de la variable a predecir
        coeficientes: Dict con pesos de cada variable
        r2_score: Bondad del ajuste
        rmse: Error cuadr√°tico medio
        historial_entrenamiento: Datos del entrenamiento
    """
    
    def __init__(self):
        self.modelo = None
        self.scaler = StandardScaler()
        self.variables_entrada = None
        self.variable_salida = 'Tiempo_Real_Ofertado'
        self.coeficientes = {}
        self.r2_score = None
        self.rmse = None
        self.mae = None
        self.historial_entrenamiento = {}
        self.datos_entrenamiento = None
        
    # ========================================================================
    # PASO 1: SELECCIONAR VARIABLES (Feature Selection)
    # ========================================================================
    
    def seleccionar_variables(self, df, umbral_correlacion=0.5):
        """
        Selecciona variables que tengan correlaci√≥n significativa con el target.
        
        Args:
            df: DataFrame limpio
            umbral_correlacion: M√≠nimo R¬≤ (varianza explicada) para incluir
        
        Returns:
            Lista de variables seleccionadas
        """
        print("\n" + "="*80)
        print("üéØ PASO 1: SELECCI√ìN DE VARIABLES")
        print("="*80)
        
        # Solo usar columnas num√©ricas (excluir Proyecto)
        df_numerico = df.select_dtypes(include=[np.number])
        correlaciones = df_numerico.corr()[self.variable_salida].drop(self.variable_salida)
        r_squared = correlaciones ** 2
        
        # Filtrar variables v√°lidas (sin NaN y con correlaci√≥n m√≠nima)
        variables_validas = r_squared[
            (~r_squared.isna()) & (r_squared.abs() >= umbral_correlacion)
        ].sort_values(ascending=False)
        
        print(f"\nüìå Umbral de correlaci√≥n (R¬≤): {umbral_correlacion}")
        print(f"\n‚úÖ Variables seleccionadas ({len(variables_validas)}):\n")
        
        for var, r2 in variables_validas.items():
            print(f"  ‚Ä¢ {var:20} ‚Üí R¬≤ = {r2:.4f} (explica {r2*100:.1f}% de varianza)")
        
        self.variables_entrada = variables_validas.index.tolist()
        self.historial_entrenamiento['variables_seleccionadas'] = self.variables_entrada
        
        return self.variables_entrada
    
    # ========================================================================
    # PASO 2: ENTRENAR MODELO
    # ========================================================================
    
    def entrenar(self, df):
        """
        Entrena el modelo de regresi√≥n lineal.
        
        Args:
            df: DataFrame limpio con variables
        """
        print("\n" + "="*80)
        print("‚öôÔ∏è  PASO 2: ENTRENAMIENTO DEL MODELO")
        print("="*80)
        
        # Preparar datos
        X = df[self.variables_entrada].values
        y = df[self.variable_salida].values
        
        print(f"\nüìä Datos de entrenamiento:")
        print(f"   ‚Ä¢ Muestras: {len(df)}")
        print(f"   ‚Ä¢ Variables: {len(self.variables_entrada)}")
        print(f"   ‚Ä¢ Rango objetivo: [{y.min():.1f}s, {y.max():.1f}s]")
        
        # Entrenar modelo
        self.modelo = LinearRegression()
        self.modelo.fit(X, y)
        
        # Predecir sobre mismos datos
        y_pred = self.modelo.predict(X)
        
        # Calcular m√©tricas
        self.r2_score = r2_score(y, y_pred)
        self.rmse = np.sqrt(mean_squared_error(y, y_pred))
        self.mae = mean_absolute_error(y, y_pred)
        
        print(f"\nüìà RESULTADOS DEL ENTRENAMIENTO:")
        print(f"   ‚Ä¢ R¬≤ score: {self.r2_score:.4f} ‚üπ Explica {self.r2_score*100:.1f}% de varianza")
        print(f"   ‚Ä¢ RMSE: {self.rmse:.2f} segundos")
        print(f"   ‚Ä¢ MAE: {self.mae:.2f} segundos")
        
        # Calcular coeficientes (pesos)
        self._calcular_pesos()
        
        # Guardar datos
        self.datos_entrenamiento = df
        self.historial_entrenamiento['r2'] = self.r2_score
        self.historial_entrenamiento['rmse'] = self.rmse
        self.historial_entrenamiento['mae'] = self.mae
        
    # ========================================================================
    # PASO 3: CALCULAR Y MOSTRAR PESOS
    # ========================================================================
    
    def _calcular_pesos(self):
        """
        Calcula e interpreta los coeficientes (pesos) del modelo.
        Esto muestra la PONDERACI√ìN de cada variable.
        """
        print(f"\n" + "="*80)
        print("‚öñÔ∏è  PONDERACI√ìN DE VARIABLES (Coeficientes)")
        print("="*80)
        
        # Intercept
        intercept = self.modelo.intercept_
        print(f"\nüìå Tiempo Base (sin variables): {intercept:.2f} segundos")
        
        # Coeficientes
        coefs = self.modelo.coef_
        self.coeficientes = {var: coef for var, coef in zip(self.variables_entrada, coefs)}
        
        # Ordenar por magnitud
        coefs_ordenados = sorted(self.coeficientes.items(), key=lambda x: abs(x[1]), reverse=True)
        
        print(f"\n‚öñÔ∏è  PESOS (de m√°s a menos importante):\n")
        print(f"  {'Variable':<20} | {'Coeficiente':>12} | Interpretaci√≥n")
        print(f"  {'-'*70}")
        
        for var, coef in coefs_ordenados:
            # Interpretaci√≥n
            if coef > 0:
                interp = f"‚Üë {abs(coef):.4f}s por unidad"
            else:
                interp = f"‚Üì {abs(coef):.4f}s por unidad"
            print(f"  {var:<20} | {coef:>12.4f} | {interp}")
        
        # An√°lisis de importancia relativa
        print(f"\nüìä IMPORTANCIA RELATIVA:")
        print(f"\n  (Comparado con la variable m√°s influyente)\n")
        
        max_coef = max(abs(c) for c in coefs)
        for var, coef in coefs_ordenados:
            importancia = (abs(coef) / max_coef) * 100
            barra = "‚ñà" * int(importancia / 5) + "‚ñë" * (20 - int(importancia / 5))
            print(f"  {var:<20} | {barra} | {importancia:5.1f}%")
        
        # Informaci√≥n adicional
        print(f"\nüí° INTERPRETACI√ìN:")
        print(f"   Si los coeficientes son similares ‚Üí Variables igualmente importantes")
        print(f"   Si hay gran diferencia ‚Üí Una o dos variables dominan el modelo")
    
    # ========================================================================
    # PASO 4: VALIDACI√ìN CRUZADA (Cross-Validation)
    # ========================================================================
    
    def validacion_cruzada(self, df, n_folds=3):
        """
        Realiza validaci√≥n cruzada k-fold para evaluar estabilidad del modelo.
        
        Args:
            df: DataFrame completo
            n_folds: N√∫mero de folds (con pocos datos, usar 3-5)
        """
        print(f"\n" + "="*80)
        print("üîÑ PASO 4: VALIDACI√ìN CRUZADA (K-Fold)")
        print("="*80)
        
        X = df[self.variables_entrada].values
        y = df[self.variable_salida].values
        
        # Configurar validaci√≥n cruzada
        kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)
        scores_r2 = cross_val_score(self.modelo, X, y, cv=kfold, scoring='r2')
        scores_rmse = -cross_val_score(self.modelo, X, y, cv=kfold, scoring='neg_mean_squared_error')
        scores_rmse = np.sqrt(scores_rmse)
        
        print(f"\nüìä Resultados de {n_folds}-Fold Cross-Validation:\n")
        print(f"  R¬≤ Scores:")
        for i, score in enumerate(scores_r2, 1):
            print(f"    Fold {i}: {score:.4f}")
        print(f"    MEDIA: {scores_r2.mean():.4f} ¬± {scores_r2.std():.4f}")
        
        print(f"\n  RMSE Scores (segundos):")
        for i, score in enumerate(scores_rmse, 1):
            print(f"    Fold {i}: {score:.2f}s")
        print(f"    MEDIA: {scores_rmse.mean():.2f}s ¬± {scores_rmse.std():.2f}s")
        
        self.historial_entrenamiento['cv_r2'] = {
            'media': scores_r2.mean(),
            'std': scores_r2.std(),
            'scores': scores_r2.tolist()
        }
        self.historial_entrenamiento['cv_rmse'] = {
            'media': scores_rmse.mean(),
            'std': scores_rmse.std(),
            'scores': scores_rmse.tolist()
        }
        
        # Interpretaci√≥n
        if scores_r2.std() < 0.1:
            print(f"\n  ‚úÖ Modelo estable (baja varianza entre folds)")
        else:
            print(f"\n  ‚ö†Ô∏è  Modelo inestable (varianza alta entre folds)")
            print(f"     ‚Üí Puede haber sobrefitting o datos muy variados")
    
    # ========================================================================
    # PASO 5: AN√ÅLISIS DE RESIDUOS
    # ========================================================================
    
    def analizar_residuos(self, df):
        """
        Analiza los residuos (errores) del modelo.
        Los residuos deben ser aleatorios y normalmente distribuidos.
        """
        print(f"\n" + "="*80)
        print("üìâ PASO 5: AN√ÅLISIS DE RESIDUOS")
        print("="*80)
        
        X = df[self.variables_entrada].values
        y = df[self.variable_salida].values
        y_pred = self.modelo.predict(X)
        residuos = y - y_pred
        
        print(f"\nüìä Estad√≠sticas de residuos:\n")
        print(f"   Media: {residuos.mean():.4f} (debe ser ‚âà 0)")
        print(f"   Std Dev: {residuos.std():.4f}")
        print(f"   Min: {residuos.min():.4f}")
        print(f"   Max: {residuos.max():.4f}")
        
        # Mostrar predicciones vs reales
        print(f"\nüìã Comparaci√≥n Predicho vs Real:\n")
        print(f"  {'Proyecto':<20} | {'Real':>8} | {'Predicho':>8} | {'Error':>8} | {'% Error':>8}")
        print(f"  {'-'*70}")
        
        for i, proyecto in enumerate(df['Proyecto'].values):
            error = residuos[i]
            pct_error = (error / y[i]) * 100
            print(f"  {proyecto:<20} | {y[i]:>8.1f}s | {y_pred[i]:>8.1f}s | {error:>8.2f}s | {pct_error:>7.1f}%")
        
        self.historial_entrenamiento['residuos'] = residuos.tolist()
    
    # ========================================================================
    # PREDICCI√ìN
    # ========================================================================
    
    def predecir(self, datos_entrada):
        """
        Realiza predicci√≥n con un conjunto de variables.
        
        Args:
            datos_entrada: Dict con {variable: valor}
            
        Returns:
            Tiempo predicho y explicaci√≥n del c√°lculo
        """
        if self.modelo is None:
            raise ValueError("Modelo no entrenado. Ejecuta .entrenar() primero.")
        
        # Validar entrada
        for var in self.variables_entrada:
            if var not in datos_entrada:
                raise ValueError(f"Falta variable: {var}")
        
        # Preparar datos
        X = np.array([[datos_entrada[var] for var in self.variables_entrada]])
        tiempo_predicho = self.modelo.predict(X)[0]
        
        # Explicaci√≥n detallada del c√°lculo
        explicacion = {
            'tiempo_base': float(self.modelo.intercept_),
            'aportaciones': {},
            'tiempo_total': float(tiempo_predicho)
        }
        
        for var, coef in self.coeficientes.items():
            aportacion = coef * datos_entrada[var]
            explicacion['aportaciones'][var] = {
                'valor': float(datos_entrada[var]),
                'coeficiente': float(coef),
                'aportacion': float(aportacion)
            }
        
        return tiempo_predicho, explicacion
    
    # ========================================================================
    # AN√ÅLISIS DE SENSIBILIDAD
    # ========================================================================
    
    def analisis_sensibilidad(self, datos_base, variable_ajuste, rango=(-20, 20), pasos=11):
        """
        Analiza c√≥mo cambia el tiempo predicho al variar una variable.
        
        Args:
            datos_base: Dict con configuraci√≥n base
            variable_ajuste: Variable a variar
            rango: Tupla (min%, max%) para variar
            pasos: N√∫mero de puntos a calcular
            
        Returns:
            Lista de predicciones con variaciones
        """
        resultado = []
        valor_base = datos_base[variable_ajuste]
        
        variaciones = np.linspace(rango[0], rango[1], pasos)
        
        for pct in variaciones:
            datos_mod = datos_base.copy()
            datos_mod[variable_ajuste] = valor_base * (1 + pct/100)
            tiempo, _ = self.predecir(datos_mod)
            
            resultado.append({
                'variacion_pct': float(pct),
                'valor': float(datos_mod[variable_ajuste]),
                'tiempo_predicho': float(tiempo),
                'cambio_tiempo': float(tiempo - resultado[0]['tiempo_predicho']) if resultado else 0.0
            })
        
        return resultado
    
    # ========================================================================
    # GUARDAR/CARGAR MODELO
    # ========================================================================
    
    def guardar(self, ruta_modelo='modelo_regresion.pkl', ruta_config='config_modelo.json'):
        """Guarda el modelo entrenado"""
        with open(ruta_modelo, 'wb') as f:
            pickle.dump(self.modelo, f)
        
        config = {
            'variables_entrada': self.variables_entrada,
            'variable_salida': self.variable_salida,
            'coeficientes': self.coeficientes,
            'r2_score': float(self.r2_score),
            'rmse': float(self.rmse),
            'mae': float(self.mae),
            'intercept': float(self.modelo.intercept_)
        }
        
        with open(ruta_config, 'w') as f:
            json.dump(config, f, indent=4)
        
        print(f"‚úÖ Modelo guardado: {ruta_modelo}")
        print(f"‚úÖ Configuraci√≥n guardada: {ruta_config}")
    
    def cargar(self, ruta_modelo='modelo_regresion.pkl', ruta_config='config_modelo.json'):
        """Carga el modelo entrenado"""
        with open(ruta_modelo, 'rb') as f:
            self.modelo = pickle.load(f)
        
        with open(ruta_config, 'r') as f:
            config = json.load(f)
        
        self.variables_entrada = config['variables_entrada']
        self.coeficientes = config['coeficientes']
        self.r2_score = config['r2_score']
        self.rmse = config['rmse']
        self.mae = config['mae']
        
        print(f"‚úÖ Modelo cargado: {ruta_modelo}")
        print(f"‚úÖ Configuraci√≥n cargada: {ruta_config}")
    
    # ========================================================================
    # REPORTE COMPLETO
    # ========================================================================
    
    def generar_reporte(self, ruta_archivo='reporte_modelo.txt'):
        """Genera reporte completo del modelo"""
        with open(ruta_archivo, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("REPORTE COMPLETO DEL MODELO DE REGRESI√ìN LINEAL\n")
            f.write("="*80 + "\n\n")
            
            f.write("M√âTRICAS DE CALIDAD:\n")
            f.write(f"  R¬≤ Score: {self.r2_score:.4f}\n")
            f.write(f"  RMSE: {self.rmse:.2f} segundos\n")
            f.write(f"  MAE: {self.mae:.2f} segundos\n\n")
            
            f.write("COEFICIENTES:\n")
            f.write(f"  Intercept: {self.modelo.intercept_:.4f}\n")
            for var, coef in sorted(self.coeficientes.items(), key=lambda x: abs(x[1]), reverse=True):
                f.write(f"  {var}: {coef:.4f}\n")
            
            f.write("\n" + "="*80 + "\n")
        
        print(f"‚úÖ Reporte guardado: {ruta_archivo}")


# ============================================================================
# SCRIPT DE DEMOSTRACI√ìN
# ============================================================================

if __name__ == "__main__":
    
    # Cargar datos limpios
    df = pd.read_csv('base_datos_limpia.csv')
    
    # Crear y entrenar modelo
    modelo = ModeloRegresionLineal()
    
    # Paso 1: Seleccionar variables
    modelo.seleccionar_variables(df, umbral_correlacion=0.5)
    
    # Paso 2: Entrenar
    modelo.entrenar(df)
    
    # Paso 3: Pesos (autom√°tico en entrenar)
    
    # Paso 4: Validaci√≥n cruzada
    modelo.validacion_cruzada(df, n_folds=3)
    
    # Paso 5: An√°lisis de residuos
    modelo.analizar_residuos(df)
    
    # Guardar modelo
    modelo.guardar()
    
    # Generar reporte
    modelo.generar_reporte()
    
    print("\n" + "="*80)
    print("‚úÖ ENTRENAMIENTO COMPLETADO")
    print("="*80)
